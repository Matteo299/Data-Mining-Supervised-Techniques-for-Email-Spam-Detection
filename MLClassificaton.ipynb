{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Approaches Comparison to Spam Detection\n",
    "In this notebook different classification methods to **spam detection** are compared.\n",
    "The algorithms compared are:\n",
    "- Naive Bayes\n",
    "- Support Vector Machine\n",
    "- Random Forest\n",
    "- K Nearest Neighbor\n",
    "- Decision Tree\n",
    "\n",
    "Each method is tested on:\n",
    "- Raw email text\n",
    "- Cleaned email text\n",
    "- Stemmed email text\n",
    "- Lemmatized email text\n",
    "\n",
    "Also two different vectorizers methods are tested:\n",
    "- Term Frequency - Inverse Document Frequency (TF-IDF) Vectorizer\n",
    "- Count Vectorizer\n",
    "\n",
    "The purpose of this notebook is to generate many graphs comparing the algorithms performance (using different input data and vectorizer) in order to find the best suited approaches for this task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "from random import shuffle\n",
    "%matplotlib inline\n",
    "matplotlib.use('Agg')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing dataset: \n",
    "In order to apply classification algorithms to our data, we need to transform the alphanumeric emails text into vectors which are able to represent the information contained in an email using a numeric format.\n",
    "The vectorizers tested are:\n",
    "- **Count vectorizer**: one of the simplest vectorization methods that uses is bag-of-words (BoW) representation. A BoW vector has the length of the entire vocabulary — that is, the set of unique words in the corpus. The vector’s values represent the frequency with which each word appears in a given text passage.\n",
    "\n",
    "- **TF-IDF vectorizer**: this techinque attempts to give higher relevance scores to words that occur in fewer documents within the corpus. TF-IDF measures the frequency of a word in a text against its overall frequency in the corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset is read from the csv\n",
    "dataset = pd.read_csv(\"EmailDatasetCleaned.csv\", index_col=0)\n",
    "\n",
    "dataset.columns = ['email', 'label', 'length', 'clean_email_text', \n",
    "                   'tokenized_email_text', 'nonstop_email_text', 'stemmed_email_text', \n",
    "                   'lemmatized_email_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_email_text</th>\n",
       "      <th>tokenized_email_text</th>\n",
       "      <th>nonstop_email_text</th>\n",
       "      <th>stemmed_email_text</th>\n",
       "      <th>lemmatized_email_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>Subject: college degree online !\\n</td>\n",
       "      <td>spam</td>\n",
       "      <td>33</td>\n",
       "      <td>subject college degree online</td>\n",
       "      <td>['subject', 'college', 'degree', 'online']</td>\n",
       "      <td>['subject', 'college', 'degree', 'online']</td>\n",
       "      <td>['subject', 'colleg', 'degre', 'onlin']</td>\n",
       "      <td>['subject', 'college', 'degree', 'online']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21166</th>\n",
       "      <td>Subject: purchase steroids online\\n hi !\\n the...</td>\n",
       "      <td>spam</td>\n",
       "      <td>591</td>\n",
       "      <td>subject purchase steroids online hi  the stero...</td>\n",
       "      <td>['subject', 'purchase', 'steroids', 'online', ...</td>\n",
       "      <td>['subject', 'purchase', 'steroids', 'online', ...</td>\n",
       "      <td>['subject', 'purchas', 'steroid', 'onlin', 'hi...</td>\n",
       "      <td>['subject', 'purchase', 'steroid', 'online', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5353</th>\n",
       "      <td>Subject: moneycentral : 6 routes to retire ric...</td>\n",
       "      <td>ham</td>\n",
       "      <td>60</td>\n",
       "      <td>subject moneycentral   routes to retire rich e...</td>\n",
       "      <td>['subject', 'moneycentral', 'routes', 'to', 'r...</td>\n",
       "      <td>['subject', 'moneycentral', 'routes', 'retire'...</td>\n",
       "      <td>['subject', 'moneycentr', 'rout', 'retir', 'ri...</td>\n",
       "      <td>['subject', 'moneycentral', 'route', 'retire',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9827</th>\n",
       "      <td>Subject: enron / hpl actuals for february 2 - ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>222</td>\n",
       "      <td>subject enron  hpl actuals for february      f...</td>\n",
       "      <td>['subject', 'enron', 'hpl', 'actuals', 'for', ...</td>\n",
       "      <td>['subject', 'enron', 'hpl', 'actuals', 'februa...</td>\n",
       "      <td>['subject', 'enron', 'hpl', 'actual', 'februar...</td>\n",
       "      <td>['subject', 'enron', 'hpl', 'actuals', 'februa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12128</th>\n",
       "      <td>Subject: epe lending / day - ahead short for 8...</td>\n",
       "      <td>ham</td>\n",
       "      <td>1258</td>\n",
       "      <td>subject epe lending  day  ahead short for    w...</td>\n",
       "      <td>['subject', 'epe', 'lending', 'day', 'ahead', ...</td>\n",
       "      <td>['subject', 'epe', 'lending', 'day', 'ahead', ...</td>\n",
       "      <td>['subject', 'epe', 'lend', 'day', 'ahead', 'sh...</td>\n",
       "      <td>['subject', 'epe', 'lending', 'day', 'ahead', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   email label  length  \\\n",
       "24976                 Subject: college degree online !\\n  spam      33   \n",
       "21166  Subject: purchase steroids online\\n hi !\\n the...  spam     591   \n",
       "5353   Subject: moneycentral : 6 routes to retire ric...   ham      60   \n",
       "9827   Subject: enron / hpl actuals for february 2 - ...   ham     222   \n",
       "12128  Subject: epe lending / day - ahead short for 8...   ham    1258   \n",
       "\n",
       "                                        clean_email_text  \\\n",
       "24976                      subject college degree online   \n",
       "21166  subject purchase steroids online hi  the stero...   \n",
       "5353   subject moneycentral   routes to retire rich e...   \n",
       "9827   subject enron  hpl actuals for february      f...   \n",
       "12128  subject epe lending  day  ahead short for    w...   \n",
       "\n",
       "                                    tokenized_email_text  \\\n",
       "24976         ['subject', 'college', 'degree', 'online']   \n",
       "21166  ['subject', 'purchase', 'steroids', 'online', ...   \n",
       "5353   ['subject', 'moneycentral', 'routes', 'to', 'r...   \n",
       "9827   ['subject', 'enron', 'hpl', 'actuals', 'for', ...   \n",
       "12128  ['subject', 'epe', 'lending', 'day', 'ahead', ...   \n",
       "\n",
       "                                      nonstop_email_text  \\\n",
       "24976         ['subject', 'college', 'degree', 'online']   \n",
       "21166  ['subject', 'purchase', 'steroids', 'online', ...   \n",
       "5353   ['subject', 'moneycentral', 'routes', 'retire'...   \n",
       "9827   ['subject', 'enron', 'hpl', 'actuals', 'februa...   \n",
       "12128  ['subject', 'epe', 'lending', 'day', 'ahead', ...   \n",
       "\n",
       "                                      stemmed_email_text  \\\n",
       "24976            ['subject', 'colleg', 'degre', 'onlin']   \n",
       "21166  ['subject', 'purchas', 'steroid', 'onlin', 'hi...   \n",
       "5353   ['subject', 'moneycentr', 'rout', 'retir', 'ri...   \n",
       "9827   ['subject', 'enron', 'hpl', 'actual', 'februar...   \n",
       "12128  ['subject', 'epe', 'lend', 'day', 'ahead', 'sh...   \n",
       "\n",
       "                                   lemmatized_email_text  \n",
       "24976         ['subject', 'college', 'degree', 'online']  \n",
       "21166  ['subject', 'purchase', 'steroid', 'online', '...  \n",
       "5353   ['subject', 'moneycentral', 'route', 'retire',...  \n",
       "9827   ['subject', 'enron', 'hpl', 'actuals', 'februa...  \n",
       "12128  ['subject', 'epe', 'lending', 'day', 'ahead', ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random samples from the dataset are printed\n",
    "dataset = dataset.sample(frac=1)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer costants\n",
    "TFIDF = 0\n",
    "COUNT = 1\n",
    "\n",
    "# Algorithm constants\n",
    "BAYES = 0\n",
    "SVM = 1\n",
    "RF = 2\n",
    "KNN = 3\n",
    "DT = 4\n",
    "\n",
    "# Different formats of the input emails\n",
    "inputs = {elem: i for i,elem in enumerate(['email','clean_email_text',\n",
    "                                           'stemmed_email_text','lemmatized_email_text'])}\n",
    "\n",
    "# Matrix containing numeric features using different formats and vectorizers\n",
    "features = [[] for x in range(2)]\n",
    "\n",
    "# 4 dimensional array containing scores for each algorithm, using different mail formats and vectorizers\n",
    "score = [[[[] for z in range(4)] for y in range(2)] for x in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "for type in inputs.keys():\n",
    "    if type == 'email' or type == 'clean_email_text':\n",
    "        emails = [o for o in dataset[type]]\n",
    "    else:\n",
    "        emails = [o.strip('[]\\'').replace('\\', \\'',' ') for o in dataset[type]]\n",
    "    features[TFIDF].append(tfidf_vectorizer.fit_transform(emails))\n",
    "    features[COUNT].append(count_vectorizer.fit_transform(emails))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Classification Algorithms for Comparative Analysis\n",
    "In this section the classification algorithms for comparative analysis are applied to see which one will yield the best results in terms of accuracy, precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test matrices are initialized\n",
    "X_train = [[] for x in range(2)]\n",
    "X_test = [[] for x in range(2)]\n",
    "y_train = [[] for x in range(2)]\n",
    "y_test = [[] for x in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Splits are performed\n",
    "for i in range(2):\n",
    "    for j in inputs.values() :\n",
    "        a, b, c, d = (train_test_split(features[i][j], dataset['label'], test_size=0.2, random_state=111))\n",
    "        X_train[i].append(a)\n",
    "        X_test[i].append(b)\n",
    "        y_train[i].append(c)\n",
    "        y_test[i].append(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "It is a classification technique based on Bayes' Theorem with an assumption of independence among predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2): # for each vectorizer\n",
    "    for j in inputs.values() : # for each input format\n",
    "        Xtrain = X_train[i][j]\n",
    "        Xtest = X_test[i][j]\n",
    "        ytrain = y_train[i][j]\n",
    "        ytest = y_test[i][j]\n",
    "        clf = MultinomialNB(alpha=0.2) # classifier is initialized\n",
    "        clf.fit(Xtrain, ytrain) # training is performed\n",
    "        y_pred_nb = clf.predict(Xtest) # testing\n",
    "        # Metrics are saved\n",
    "        acc = round(accuracy_score(ytest,y_pred_nb),5)\n",
    "        pre, rec, _, _ = precision_recall_fscore_support(ytest, y_pred_nb, pos_label='spam', average='binary')\n",
    "        score[BAYES][i][j] = (acc, round(pre,5), round(rec,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the dataset into classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='sigmoid', gamma=1.0) # classifier is initialized\n",
    "for i in range(2): # for each vectorizer\n",
    "    for j in inputs.values() : # for each input format\n",
    "        Xtrain = X_train[i][j]\n",
    "        Xtest = X_test[i][j]\n",
    "        ytrain = y_train[i][j]\n",
    "        ytest = y_test[i][j]\n",
    "        svc.fit(Xtrain, ytrain) # training is performed\n",
    "        y_pred_svm = svc.predict(Xtest) # testing\n",
    "        # Metrics are saved\n",
    "        acc = round(accuracy_score(ytest,y_pred_svm),5)\n",
    "        pre, rec, _, _ = precision_recall_fscore_support(ytest, y_pred_svm, pos_label='spam', average='binary')\n",
    "        score[SVM][i][j] = (acc, round(pre,5), round(rec,5))\n",
    "        # DEBUG LINE: print(\"Run \"+str(i)+\",\"+str(j)+\" = \" + str(score[SVM][i][j]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2): # for each vectorizer\n",
    "    for j in inputs.values() : # for each input format\n",
    "        Xtrain = X_train[i][j]\n",
    "        Xtest = X_test[i][j]\n",
    "        ytrain = y_train[i][j]\n",
    "        ytest = y_test[i][j]\n",
    "        rf = RandomForestClassifier(n_estimators=200, max_depth=20, n_jobs=-1) # classifier is initialized\n",
    "        rf_model = rf.fit(Xtrain, ytrain) # training is performed\n",
    "        y_pred_rf = rf_model.predict(Xtest) # testing\n",
    "        # Metrics are saved\n",
    "        acc = round(accuracy_score(ytest,y_pred_rf),5)\n",
    "        pre, rec, _, _ = precision_recall_fscore_support(ytest, y_pred_rf, pos_label='spam', average='binary')\n",
    "        score[RF][i][j] = (acc, round(pre,5), round(rec,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors\n",
    "\n",
    "K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2): # for each vectorizer\n",
    "    for j in inputs.values() : # for each input format\n",
    "        Xtrain = X_train[i][j]\n",
    "        Xtest = X_test[i][j]\n",
    "        ytrain = y_train[i][j]\n",
    "        ytest = y_test[i][j]\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, weights='uniform',algorithm='auto', \n",
    "                                   p=1, metric='euclidean', n_jobs=-1) # classifier is initialized\n",
    "        knn.fit(Xtrain, ytrain) # training is performed\n",
    "        y_pred_knn = knn.predict(Xtest) # testing\n",
    "        # Metrics are saved\n",
    "        acc = round(accuracy_score(ytest,y_pred_knn),5)\n",
    "        pre, rec, _, _ = precision_recall_fscore_support(ytest, y_pred_knn, \n",
    "                                                         pos_label='spam', average='binary')\n",
    "        score[KNN][i][j] = (acc, round(pre,5), round(rec,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "It is a simple and effective predictive modeling approach used in many classification and regression problems. The training process involves building a tree structure in which each branch recursively splits the dataset into two subsets based on the values of a selected feature. The leaves of the tree represent classifications indicating the predicted labels of the instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2): # for each vectorizer\n",
    "    for j in inputs.values() : # for each input format\n",
    "        Xtrain = X_train[i][j]\n",
    "        Xtest = X_test[i][j]\n",
    "        ytrain = y_train[i][j]\n",
    "        ytest = y_test[i][j]\n",
    "        dt = DecisionTreeClassifier() # classifier is initialized\n",
    "        dt.fit(Xtrain, ytrain) # training is performed\n",
    "        y_pred_dt = dt.predict(Xtest) # testing\n",
    "        # Metrics are saved\n",
    "        acc = round(accuracy_score(ytest,y_pred_dt),5)\n",
    "        pre, rec, _, _ = precision_recall_fscore_support(ytest, y_pred_dt, \n",
    "                                                         pos_label='spam', average='binary')\n",
    "        score[DT][i][j] = (acc, round(pre,5), round(rec,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "In this section results are aggregated into graphs and saved as images in the Result directory.\n",
    "In order to decide the best approaches, three metrics are considered:\n",
    "- **Accuracy**: it is the fraction of successful predictions with respect to the total number of emails.\n",
    "In our case the dataset is quite balanced so accuracy should be a reliable metric.\n",
    "\n",
    "- **Precision**: it is the fraction of spam emails classified as spam with respect to the total number of emails classified as spam. The better the precision, the lower are false positive samples.\n",
    "\n",
    "- **Recall**: it is the fraction of spam emails classified as spam with respect to the total number of spam emails. The better the recall, the lower are false negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function allows to change the format of the score matrix to be used for plotting results\n",
    "def change_format(matrix):\n",
    "  a = np.concatenate((matrix[0],matrix[1]))\n",
    "  b = np.transpose(a)\n",
    "  b = [tuple(x) for x in b]\n",
    "  return b\n",
    "\n",
    "# Dictionary with the classifiers and their indexes\n",
    "classifiers = {\"Bayes\":0,\"SVM\":1,\"Random Forest\":2,\"KNN\":3,\"Decision Tree\":4}\n",
    "\n",
    "# Tuple with different combinations of vectorizer - email format.\n",
    "formats = (\"TFIDF - Raw\", \"TFIDF - Clean\", \"TFIDF - Stemmed\",\"TFIDF - Lemmatized\",\n",
    "            \"COUNT - Raw\", \"COUNT - Clean\", \"COUNT - Stemmed\",\"COUNT - Lemmatized\")\n",
    "\n",
    "# Lists to save best approaches for accuracy/precisio/recall\n",
    "best_acc = []\n",
    "best_pre = []\n",
    "best_rec = []\n",
    "best_acc_method = []\n",
    "best_pre_method = []\n",
    "best_rec_method = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code plots accuracies, precision and recalls for a single algorithm considering all the \n",
    "# vecorizer-format combinations.\n",
    "\n",
    "for elem in classifiers:\n",
    "\n",
    "    output_data = change_format(np.copy(score[classifiers[elem]]))\n",
    "\n",
    "    metrics = {\n",
    "        'Accuracy': output_data[0],\n",
    "        'Precision': output_data[1],\n",
    "        'Recall': output_data[2],\n",
    "    }\n",
    "\n",
    "    best_acc.append(np.max(metrics[\"Accuracy\"]))\n",
    "    best_acc_method.append(formats[np.argmax(metrics[\"Accuracy\"])])\n",
    "\n",
    "    best_pre.append(np.max(metrics[\"Precision\"]))\n",
    "    best_pre_method.append(formats[np.argmax(metrics[\"Precision\"])])\n",
    "\n",
    "    best_rec.append(np.max(metrics[\"Recall\"]))\n",
    "    best_rec_method.append(formats[np.argmax(metrics[\"Recall\"])])\n",
    "\n",
    "    x = np.arange(len(formats))\n",
    "    width = 0.25\n",
    "    multiplier = 0\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained',figsize=(20, 10))\n",
    "\n",
    "    for attribute, measurement in metrics.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "\n",
    "    ax.set_title(elem + ' Scores')\n",
    "    ax.set_xticks(x + width, formats)\n",
    "    ax.legend(loc='lower left')\n",
    "    ax.set_ylim(0.6, 1.03)\n",
    "\n",
    "    plt.savefig('Results/'+elem+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code plots, for each algorithm, the settings (vectorizer/format) that allows to achieve\n",
    "# the best accuracy.\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained',figsize=(14, 8))\n",
    "\n",
    "algos = ['Bayes \\n' + best_acc_method[0], 'SVM\\n' + best_acc_method[1], \n",
    "         'Random Forest\\n' + best_acc_method[2], 'KNN\\n' + best_acc_method[3], \n",
    "         'Decision Tree\\n' + best_acc_method[4]]\n",
    "\n",
    "gr=sns.barplot(x=algos,y=best_acc,palette=\"GnBu\")\n",
    "ax.set_ylabel(\"Accuracy of ML Algorithms\", fontsize=16)\n",
    "ax.tick_params(labelsize=15)\n",
    "gr.bar_label(gr.containers[0], fontsize=16)\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "\n",
    "plt.savefig('Results/ApproachesBestAccuracy.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code plots, for each algorithm, the settings (vectorizer/format) that allows to achieve\n",
    "# the best precision.\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained',figsize=(14, 8))\n",
    "\n",
    "algos = ['Bayes \\n' + best_pre_method[0], 'SVM\\n' + best_pre_method[1], \n",
    "         'Random Forest\\n' + best_pre_method[2], 'KNN\\n' + best_pre_method[3], \n",
    "         'Decision Tree\\n' + best_pre_method[4]]\n",
    "\n",
    "gr=sns.barplot(x=algos,y=best_pre,palette=\"GnBu\")\n",
    "ax.set_ylabel(\"Precision of ML Algorithms\", fontsize=16)\n",
    "ax.tick_params(labelsize=15)\n",
    "gr.bar_label(gr.containers[0], fontsize=16)\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "\n",
    "plt.savefig('Results/ApproachesBestPrecision.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code plots, for each algorithm, the settings (vectorizer/format) that allows to achieve\n",
    "# the best recall.\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained',figsize=(14, 8))\n",
    "\n",
    "algos = ['Bayes \\n' + best_rec_method[0], 'SVM\\n' + best_rec_method[1], \n",
    "         'Random Forest\\n' + best_rec_method[2], 'KNN\\n' + best_rec_method[3], \n",
    "         'Decision Tree\\n' + best_rec_method[4]]\n",
    "\n",
    "gr=sns.barplot(x=algos,y=best_rec,palette=\"GnBu\")\n",
    "ax.set_ylabel(\"Recall of ML Algorithms\", fontsize=16)\n",
    "ax.tick_params(labelsize=15)\n",
    "gr.bar_label(gr.containers[0], fontsize=16)\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "\n",
    "plt.savefig('Results/ApproachesBestRecall.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
